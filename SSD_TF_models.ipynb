{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Michal287/computer_vision/blob/main/SSD_TF_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IoCmB4Md3pC"
      },
      "source": [
        "# Clone TFModels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zZAqv8udwel",
        "outputId": "86574562-e416-4cd2-a8b1-1b29283ac8ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 3934, done.\u001b[K\n",
            "remote: Counting objects: 100% (3934/3934), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3050/3050), done.\u001b[K\n",
            "remote: Total 3934 (delta 1139), reused 1885 (delta 830), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3934/3934), 49.69 MiB | 17.12 MiB/s, done.\n",
            "Resolving deltas: 100% (1139/1139), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone --depth 1 https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVmmFLK2d_nz"
      },
      "source": [
        "# Install Object Detection API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w3cin2MeDF-",
        "outputId": "26563f1b-071f-4626-93c1-a82eb361fb23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing /content/models/research\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting avro-python3 (from object-detection==0.1)\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting apache-beam (from object-detection==0.1)\n",
            "  Downloading apache_beam-2.49.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.6/14.6 MB 64.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (9.4.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (4.9.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.7.1)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (0.29.36)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (21.6.0)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.16.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.0.6)\n",
            "Collecting lvis (from object-detection==0.1)\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.10.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.5.3)\n",
            "Collecting tf-models-official>=2.5.1 (from object-detection==0.1)\n",
            "  Downloading tf_models_official-2.13.1-py2.py3-none-any.whl (2.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.6/2.6 MB 69.5 MB/s eta 0:00:00\n",
            "Collecting tensorflow_io (from object-detection==0.1)\n",
            "  Downloading tensorflow_io-0.33.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (28.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 28.6/28.6 MB 46.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.12.0)\n",
            "Collecting pyparsing==2.4.7 (from object-detection==0.1)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.8/67.8 kB 6.9 MB/s eta 0:00:00\n",
            "Collecting sacrebleu<=2.2.0 (from object-detection==0.1)\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.6/116.6 kB 12.5 MB/s eta 0:00:00\n",
            "Collecting portalocker (from sacrebleu<=2.2.0->object-detection==0.1)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.10.31)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.23.5)\n",
            "Collecting colorama (from sacrebleu<=2.2.0->object-detection==0.1)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.84.0)\n",
            "Collecting immutabledict (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading immutabledict-3.0.0-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.16)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.8.0.74)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (9.0.0)\n",
            "Collecting pyyaml<5.4.0,>=5.1 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 269.4/269.4 kB 26.4 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting sentencepiece (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 79.2 MB/s eta 0:00:00\n",
            "Collecting seqeval (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 5.3 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.9.2)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.14.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 241.2/241.2 kB 22.2 MB/s eta 0:00:00\n",
            "Collecting tensorflow-text~=2.13.0 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.5/6.5 MB 75.6 MB/s eta 0:00:00\n",
            "Collecting tensorflow~=2.13.0 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 524.1/524.1 MB 2.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2022.7.1)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim->object-detection==0.1) (1.4.0)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam->object-detection==0.1)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 89.7/89.7 kB 11.7 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting orjson<4.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading orjson-3.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (140 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 140.3/140.3 kB 16.7 MB/s eta 0:00:00\n",
            "Collecting dill<0.3.2,>=0.3.1.1 (from apache-beam->object-detection==0.1)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 152.0/152.0 kB 18.7 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam->object-detection==0.1)\n",
            "  Downloading fastavro-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.7/2.7 MB 104.4 MB/s eta 0:00:00\n",
            "Collecting fasteners<1.0,>=0.3 (from apache-beam->object-detection==0.1)\n",
            "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.56.2)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading hdfs-2.7.2.tar.gz (43 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.4/43.4 kB 5.4 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.21.0)\n",
            "Collecting objsize<0.7.0,>=0.6.1 (from apache-beam->object-detection==0.1)\n",
            "  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading pymongo-4.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (603 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 603.6/603.6 kB 48.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.22.3)\n",
            "Requirement already satisfied: protobuf<4.24.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (3.20.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (4.7.1)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.7/2.7 MB 103.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pyarrow<12.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (4.7.0.72)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (4.42.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (23.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.33.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io->object-detection==0.1) (0.33.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2023.7.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.26.16)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.0.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam->object-detection==0.1)\n",
            "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 300.4/300.4 kB 31.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.4)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n",
            "Collecting keras (from object-detection==0.1)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 84.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (67.7.2)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 115.4 MB/s eta 0:00:00\n",
            "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 440.8/440.8 kB 39.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (2.3.0)\n",
            "Collecting typing-extensions>=3.7.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (8.1.6)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.13.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (0.41.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (6.0.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.16.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.60.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.3.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (2.3.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
            "Building wheels for collected packages: object-detection, avro-python3, crcmod, dill, hdfs, pyyaml, seqeval, docopt\n",
            "  Building wheel for object-detection (setup.py): started\n",
            "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1697187 sha256=31c011c87a3c9f763a3d84a1833a366fd305b64844d77f0fee026520bf659f53\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gj6trgj1/wheels/53/dd/70/2de274d6c443c69d367bd6a5606f95e5a6df61aacf1435ec0d\n",
            "  Building wheel for avro-python3 (setup.py): started\n",
            "  Building wheel for avro-python3 (setup.py): finished with status 'done'\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43991 sha256=a8c7261b8311ab568319d342111159f273ff8e59b1353da529676365e773d9d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\n",
            "  Building wheel for crcmod (setup.py): started\n",
            "  Building wheel for crcmod (setup.py): finished with status 'done'\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31401 sha256=ef476a08115484511ea9ec8b700492e676910cae53e0cb822085c3f83b6c9432\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py): started\n",
            "  Building wheel for dill (setup.py): finished with status 'done'\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78543 sha256=658e5a5b5b9837eb2a10785eab53dacb93660b81e6a8f6c93ebec3a798f1d0df\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py): started\n",
            "  Building wheel for hdfs (setup.py): finished with status 'done'\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.2-py3-none-any.whl size=34168 sha256=5916aef062cc9f67b7e18aa80999461570fb1c8ea0c6bb2127fe93a3ad97e003\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/39/8e/e1905de9af8ae74911cd3e53e721995cd230816f63776e5825\n",
            "  Building wheel for pyyaml (setup.py): started\n",
            "  Building wheel for pyyaml (setup.py): finished with status 'done'\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp310-cp310-linux_x86_64.whl size=44635 sha256=bbc7e345ad833c996164c689a2f7d0fdec9627f28989fb332a6cc37dd63071aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/a9/6a/d0a6981a8dbb698845178818642f72ce179f14336908c7df01\n",
            "  Building wheel for seqeval (setup.py): started\n",
            "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16165 sha256=20ff399bedbb53da69a37b982142c49250204462945225a33a62e0d7f7f4ee87\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "  Building wheel for docopt (setup.py): started\n",
            "  Building wheel for docopt (setup.py): finished with status 'done'\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=ba610e7699ad35777b025980927f76b11ab7f8e2d3a1b1fe3f3366d0e46ed071\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built object-detection avro-python3 crcmod dill hdfs pyyaml seqeval docopt\n",
            "Installing collected packages: sentencepiece, docopt, crcmod, zstandard, typing-extensions, tensorflow-model-optimization, tensorflow_io, tensorflow-estimator, pyyaml, pyparsing, portalocker, orjson, objsize, keras, immutabledict, fasteners, fastavro, dnspython, dill, colorama, avro-python3, sacrebleu, pymongo, hdfs, seqeval, lvis, apache-beam, tensorboard, tensorflow, tensorflow-text, tf-models-official, object-detection\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.7.1\n",
            "    Uninstalling typing_extensions-4.7.1:\n",
            "      Successfully uninstalled typing_extensions-4.7.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.1\n",
            "    Uninstalling PyYAML-6.0.1:\n",
            "      Successfully uninstalled PyYAML-6.0.1\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.1\n",
            "    Uninstalling pyparsing-3.1.1:\n",
            "      Successfully uninstalled pyparsing-3.1.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "Successfully installed apache-beam-2.49.0 avro-python3-1.10.2 colorama-0.4.6 crcmod-1.7 dill-0.3.1.1 dnspython-2.4.2 docopt-0.6.2 fastavro-1.8.2 fasteners-0.18 hdfs-2.7.2 immutabledict-3.0.0 keras-2.13.1 lvis-0.5.3 object-detection-0.1 objsize-0.6.1 orjson-3.9.4 portalocker-2.7.0 pymongo-4.4.1 pyparsing-2.4.7 pyyaml-5.3.1 sacrebleu-2.2.0 sentencepiece-0.1.99 seqeval-1.2.2 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-model-optimization-0.7.5 tensorflow-text-2.13.0 tensorflow_io-0.33.0 tf-models-official-2.13.1 typing-extensions-4.5.0 zstandard-0.21.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flax 0.7.1 requires PyYAML>=5.4.1, but you have pyyaml 5.3.1 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx7vXbr5eR4b"
      },
      "source": [
        "# Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cw8nFsYeUgi",
        "outputId": "ecd59510-25b6-4408-9618-039e2c1d834b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan /content/drive/MyDrive/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 583322523 bytes (557 MiB)\n",
            "\n",
            "Extracting archive: /content/drive/MyDrive/source.zip\n",
            "--\n",
            "Path = /content/drive/MyDrive/source.zip\n",
            "Type = zip\n",
            "Physical Size = 583322523\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  2% 6 - source/image_103.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 11 - source/image_108.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% 16 - source/image_112.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 22 - source/image_118.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 26 - source/image_121.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 31 - source/image_126.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 35 - source/image_130.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 39 - source/image_134.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% 43 - source/image_138.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 47 - source/image_142.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% 50 - source/image_145.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 56 - source/image_151.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 61 - source/image_156.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 66 - source/image_161.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 71 - source/image_166.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 76 - source/image_171.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% 82 - source/image_177.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 85 - source/image_180.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% 89 - source/image_184.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% 92 - source/image_187.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% 95 - source/image_190.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41% 99 - source/image_194.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% 102 - source/image_197.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 108 - source/image_202.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 112 - source/image_206.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 117 - source/image_211.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% 120 - source/image_214.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% 121 - source/image_215.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 124 - source/image_218.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% 127 - source/image_221.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% 131 - source/image_225.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57% 134 - source/image_228.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% 139 - source/image_233.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% 146 - source/image_240.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% 150 - source/image_244.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% 153 - source/image_247.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% 158 - source/image_28.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% 163 - source/image_32.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% 167 - source/image_36.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% 172 - source/image_40.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% 175 - source/image_43.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% 179 - source/image_47.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% 183 - source/image_50.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% 189 - source/image_56.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% 194 - source/image_60.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% 198 - source/image_64.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% 204 - source/image_7.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% 209 - source/image_74.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% 214 - source/image_79.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% 219 - source/image_83.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% 225 - source/image_89.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% 229 - source/image_92.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% 234 - source/image_97.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Files: 237\n",
            "Size:       623158541\n",
            "Compressed: 583322523\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan /content/drive/MyDrive/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 287681619 bytes (275 MiB)\n",
            "\n",
            "Extracting archive: /content/drive/MyDrive/source2.zip\n",
            "--\n",
            "Path = /content/drive/MyDrive/source2.zip\n",
            "Type = zip\n",
            "Physical Size = 287681619\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  5% 5 - source2/image_217.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 12 - source2/image_225.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 16 - source2/image_230.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 20 - source2/image_234.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 26 - source2/image_241.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 27 - source2/image_242.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 32 - source2/image_247.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 36 - source2/image_252.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% 41 - source2/image_257.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% 45 - source2/image_261.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% 49 - source2/image_266.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% 55 - source2/image_272.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% 57 - source2/image_274.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% 61 - source2/image_279.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% 67 - source2/image_286.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% 70 - source2/image_289.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% 75 - source2/image_294.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78% 79 - source2/image_298.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% 84 - source2/image_303.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% 89 - source2/image_308.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% 95 - source2/image_314.png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Files: 100\n",
            "Size:       300488081\n",
            "Compressed: 287681619\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!7z x /content/drive/MyDrive/source.zip -odata/images\n",
        "!7z x /content/drive/MyDrive/source2.zip -odata/images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHCOkxmWfUlM"
      },
      "source": [
        "# Create TF-Record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUrqidDHfWm5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import json\n",
        "from object_detection.utils import dataset_util\n",
        "\n",
        "def tfrecord_creator(image, annotations_list):\n",
        "    image_tensor = tf.io.decode_image(image)\n",
        "    height, width, _ = image_tensor.shape\n",
        "\n",
        "    xmins, xmaxs, ymins, ymaxs = [], [], [], []\n",
        "    classes_text = []\n",
        "\n",
        "    for ann in annotations_list:\n",
        "        x, y, w, h = ann['bbox']\n",
        "        xmins.append(float(x) / width)\n",
        "        xmaxs.append(float(x + w) / width)\n",
        "        ymins.append(float(y) / height)\n",
        "        ymaxs.append(float(y + h) / height)\n",
        "        classes_text.append(str('Stab').encode('utf8'))\n",
        "\n",
        "    feature_dict = {\n",
        "        'image/encoded': dataset_util.bytes_feature(image.numpy()),\n",
        "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "    }\n",
        "\n",
        "    return tf.train.Example(features=tf.train.Features(feature=feature_dict))\n",
        "\n",
        "def main(coco_annotation_file, output_file, image_dir):\n",
        "    with open(coco_annotation_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    with tf.io.TFRecordWriter(output_file) as writer:\n",
        "        for item in data['images']:\n",
        "            annotations_list = [ann for ann in data['annotations'] if ann['image_id'] == item['id']]\n",
        "            if not annotations_list:  # skip images without annotations\n",
        "                continue\n",
        "            image_path = os.path.join(image_dir, item['file_name'])\n",
        "            if not os.path.exists(image_path):\n",
        "                print(f\"Image {image_path} not found.\")\n",
        "                continue\n",
        "            image = tf.io.read_file(image_path)\n",
        "            tf_example = tfrecord_creator(image, annotations_list)\n",
        "            writer.write(tf_example.SerializeToString())\n",
        "\n",
        "coco_annotation_file = '/content/data/annotations/merged_coco.json'\n",
        "output_file = '/content/data/merged_coco.tfrecord'\n",
        "image_dir = '/content/data/images'\n",
        "main(coco_annotation_file, output_file, image_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NM1bIrZP45B"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def split_tfrecord(tfrecord_path, train_path, val_path, split_ratio=0.8):\n",
        "    \"\"\"\n",
        "    Podzieli podany plik TFRecord na dwa: treningowy i walidacyjny.\n",
        "\n",
        "    Args:\n",
        "    - tfrecord_path: Ścieżka do pierwotnego pliku TFRecord.\n",
        "    - train_path: Ścieżka do nowego pliku TFRecord dla danych treningowych.\n",
        "    - val_path: Ścieżka do nowego pliku TFRecord dla danych walidacyjnych.\n",
        "    - split_ratio: Proporcja danych przeznaczonych na trening. Domyślnie 0.8 (80% na trening).\n",
        "    \"\"\"\n",
        "\n",
        "    # Wczytaj wszystkie dane z pierwotnego pliku TFRecord\n",
        "    raw_dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
        "    total_records = sum(1 for _ in raw_dataset)\n",
        "\n",
        "    # Oblicz, ile rekordów powinno być w zbiorze treningowym i walidacyjnym\n",
        "    train_size = int(total_records * split_ratio)\n",
        "    val_size = total_records - train_size\n",
        "\n",
        "    # Zapisz dane w nowych plikach TFRecord\n",
        "    with tf.io.TFRecordWriter(train_path) as train_writer, tf.io.TFRecordWriter(val_path) as val_writer:\n",
        "        for index, record in enumerate(raw_dataset):\n",
        "            if index < train_size:\n",
        "                train_writer.write(record.numpy())\n",
        "            else:\n",
        "                val_writer.write(record.numpy())\n",
        "\n",
        "# Użycie funkcji\n",
        "split_tfrecord('/content/data/merged_coco.tfrecord',\n",
        "               '/content/data/train.tfrecord',\n",
        "               '/content/data/val.tfrecord',\n",
        "               split_ratio=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ExLEY20p1L9V"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "def draw_bbox(image, bbox, class_name):\n",
        "    color = (0, 0, 255)  # czerwony w formacie RGB\n",
        "    image_h, image_w, _ = image.shape\n",
        "    start_point = (int(bbox[0] * image_w), int(bbox[1] * image_h))\n",
        "    end_point = (int(bbox[2] * image_w), int(bbox[3] * image_h))\n",
        "    image = cv2.rectangle(image, start_point, end_point, color, 2)\n",
        "    image = cv2.putText(image, class_name, (start_point[0], start_point[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
        "    return image\n",
        "\n",
        "def extract_image_from_tfrecord(tfrecord_path):\n",
        "    raw_dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
        "\n",
        "    # Aktualizacja opisu cech o bounding boxy i klasy\n",
        "    feature_description = {\n",
        "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
        "        'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
        "        'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
        "        'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
        "        'image/object/class/text': tf.io.VarLenFeature(tf.string)\n",
        "    }\n",
        "\n",
        "    def _parse_function(example_proto):\n",
        "        return tf.io.parse_single_example(example_proto, feature_description)\n",
        "\n",
        "    parsed_dataset = raw_dataset.map(_parse_function)\n",
        "    for features in parsed_dataset.take(20):  # Tu możesz zmienić liczbę obrazów, które chcesz wyświetlić. Zastąp 1 inną wartością, jeśli chcesz zobaczyć więcej obrazów.\n",
        "        image_data = features['image/encoded'].numpy()\n",
        "        image = tf.image.decode_jpeg(image_data, channels=3).numpy()\n",
        "\n",
        "        # Wyciągnięcie bounding boxów i klasy dla każdego obiektu na obrazie\n",
        "        xmin = tf.sparse.to_dense(features['image/object/bbox/xmin']).numpy()\n",
        "        ymin = tf.sparse.to_dense(features['image/object/bbox/ymin']).numpy()\n",
        "        xmax = tf.sparse.to_dense(features['image/object/bbox/xmax']).numpy()\n",
        "        ymax = tf.sparse.to_dense(features['image/object/bbox/ymax']).numpy()\n",
        "        class_texts = tf.sparse.to_dense(features['image/object/class/text']).numpy()\n",
        "\n",
        "        # Rysowanie bounding boxów i tekstu klasy na obrazie\n",
        "        for x1, y1, x2, y2, class_text in zip(xmin, ymin, xmax, ymax, class_texts):\n",
        "            bbox = [x1, y1, x2, y2]\n",
        "            class_name = class_text.decode('utf-8')\n",
        "            image = draw_bbox(image, bbox, class_name)\n",
        "\n",
        "        plt.imshow(image)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "# Podmień 'path_to_tfrecord' na ścieżkę do Twojego pliku TFRecord\n",
        "extract_image_from_tfrecord('/content/data/train.tfrecord')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYuAyd_xh81R"
      },
      "source": [
        "# Download Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdlmtV18h-UQ",
        "outputId": "20271875-fbf3-4ed4-bfca-98b19cffd1f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-08-11 08:40:02--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 142.251.10.128, 2404:6800:4003:c00::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|142.251.10.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20518283 (20M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]  19.57M  56.4MB/s    in 0.3s    \n",
            "\n",
            "2023-08-11 08:40:03 (56.4 MB/s) - ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’ saved [20518283/20518283]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
        "!tar -xf ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
        "fine_tune_checkpoint = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDwWb3FfgjOJ"
      },
      "source": [
        "# Prepare before train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hc4qBYHglHB",
        "outputId": "77113889-d2a6-402c-9e02-a82c5c03302d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-08-11 08:46:01--  https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.config\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4684 (4.6K) [text/plain]\n",
            "Saving to: ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.config’\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]   4.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-08-11 08:46:02 (48.3 MB/s) - ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.config’ saved [4684/4684]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#https://github.com/tensorflow/models/blob/master/research/object_detection/configs/tf2/faster_rcnn_resnet50_v1_fpn_640x640_coco17_tpu-8.config\n",
        "!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.config\n",
        "base_config_path = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.config'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7_SwKwIg_m5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format\n",
        "\n",
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(base_config_path, \"r\") as f:\n",
        "    proto_str = f.read()\n",
        "    text_format.Merge(proto_str, pipeline_config)\n",
        "\n",
        "pipeline_config.model.ssd.num_classes = 4\n",
        "# pipeline_config.model.ssd.add_background_class = True\n",
        "pipeline_config.train_config.batch_size = 2\n",
        "pipeline_config.train_config.fine_tune_checkpoint = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0'\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path = 'labelmap.pbtxt'\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = ['train.tfrecord']\n",
        "pipeline_config.eval_input_reader[0].label_map_path = 'labelmap.pbtxt'\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = ['test.tfrecord']\n",
        "pipeline_config.train_config.num_steps = 2000\n",
        "\n",
        "config_text = text_format.MessageToString(pipeline_config)\n",
        "with tf.io.gfile.GFile(base_config_path, \"wb\") as f:\n",
        "    f.write(config_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KPIf6x8kKAO",
        "outputId": "723b2612-be7f-4405-d207-97fad76d8ea3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model {\n",
            "  ssd {\n",
            "    num_classes: 4\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 640\n",
            "        width: 640\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: \"ssd_mobilenet_v2_fpn_keras\"\n",
            "      depth_multiplier: 1.0\n",
            "      min_depth: 16\n",
            "      conv_hyperparams {\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 4e-05\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          random_normal_initializer {\n",
            "            mean: 0.0\n",
            "            stddev: 0.01\n",
            "          }\n",
            "        }\n",
            "        activation: RELU_6\n",
            "        batch_norm {\n",
            "          decay: 0.997\n",
            "          scale: true\n",
            "          epsilon: 0.001\n",
            "        }\n",
            "      }\n",
            "      use_depthwise: true\n",
            "      override_base_feature_extractor_hyperparams: true\n",
            "      fpn {\n",
            "        min_level: 3\n",
            "        max_level: 7\n",
            "        additional_layer_depth: 128\n",
            "      }\n",
            "    }\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "        use_matmul_gather: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      weight_shared_convolutional_box_predictor {\n",
            "        conv_hyperparams {\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 4e-05\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            random_normal_initializer {\n",
            "              mean: 0.0\n",
            "              stddev: 0.01\n",
            "            }\n",
            "          }\n",
            "          activation: RELU_6\n",
            "          batch_norm {\n",
            "            decay: 0.997\n",
            "            scale: true\n",
            "            epsilon: 0.001\n",
            "          }\n",
            "        }\n",
            "        depth: 128\n",
            "        num_layers_before_predictor: 4\n",
            "        kernel_size: 3\n",
            "        class_prediction_bias_init: -4.6\n",
            "        share_prediction_tower: true\n",
            "        use_depthwise: true\n",
            "      }\n",
            "    }\n",
            "    anchor_generator {\n",
            "      multiscale_anchor_generator {\n",
            "        min_level: 3\n",
            "        max_level: 7\n",
            "        anchor_scale: 4.0\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        scales_per_octave: 2\n",
            "      }\n",
            "    }\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-08\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    loss {\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      classification_loss {\n",
            "        weighted_sigmoid_focal {\n",
            "          gamma: 2.0\n",
            "          alpha: 0.25\n",
            "        }\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    encode_background_as_zeros: true\n",
            "    normalize_loc_loss_by_codesize: true\n",
            "    inplace_batchnorm_update: true\n",
            "    freeze_batchnorm: false\n",
            "  }\n",
            "}\n",
            "train_config {\n",
            "  batch_size: 2\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    random_crop_image {\n",
            "      min_object_covered: 0.0\n",
            "      min_aspect_ratio: 0.75\n",
            "      max_aspect_ratio: 3.0\n",
            "      min_area: 0.75\n",
            "      max_area: 1.0\n",
            "      overlap_thresh: 0.0\n",
            "    }\n",
            "  }\n",
            "  sync_replicas: true\n",
            "  optimizer {\n",
            "    momentum_optimizer {\n",
            "      learning_rate {\n",
            "        cosine_decay_learning_rate {\n",
            "          learning_rate_base: 0.08\n",
            "          total_steps: 50000\n",
            "          warmup_learning_rate: 0.026666\n",
            "          warmup_steps: 1000\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  fine_tune_checkpoint: \"ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n",
            "  num_steps: 2000\n",
            "  startup_delay_steps: 0.0\n",
            "  replicas_to_aggregate: 8\n",
            "  max_number_of_boxes: 100\n",
            "  unpad_groundtruth_tensors: false\n",
            "  fine_tune_checkpoint_type: \"detection\"\n",
            "  fine_tune_checkpoint_version: V2\n",
            "}\n",
            "train_input_reader {\n",
            "  label_map_path: \"labelmap.pbtxt\"\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"train.tfrecord\"\n",
            "  }\n",
            "}\n",
            "eval_config {\n",
            "  metrics_set: \"coco_detection_metrics\"\n",
            "  use_moving_averages: false\n",
            "}\n",
            "eval_input_reader {\n",
            "  label_map_path: \"labelmap.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_epochs: 1\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"test.tfrecord\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "%cat $base_config_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BekUCGBPkW2f"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtmwIxppsK5Z"
      },
      "outputs": [],
      "source": [
        "model_dir = 'training4/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_In6XQcEkXmA",
        "outputId": "be2a616c-c242-4c58-cf12-96070400fcd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-08-11 10:01:57.833213: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-08-11 10:02:01.441800: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0811 10:02:01.442843 134875591393280 mirrored_strategy.py:419] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0811 10:02:01.465642 134875591393280 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0811 10:02:01.465810 134875591393280 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0811 10:02:01.644121 134875591393280 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['train.tfrecord']\n",
            "I0811 10:02:01.651395 134875591393280 dataset_builder.py:162] Reading unweighted datasets: ['train.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['train.tfrecord']\n",
            "I0811 10:02:01.651570 134875591393280 dataset_builder.py:79] Reading record datasets for input file: ['train.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0811 10:02:01.651629 134875591393280 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0811 10:02:01.651680 134875591393280 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0811 10:02:01.658204 134875591393280 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0811 10:02:01.677777 134875591393280 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0811 10:02:08.196521 134875591393280 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0811 10:02:11.169085 134875591393280 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0811 10:02:12.978783 134875591393280 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n",
            "I0811 10:02:25.229418 134870222227008 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I0811 10:02:33.335727 134870222227008 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0811 10:02:40.384158 134875591393280 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0811 10:02:40.387123 134875591393280 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0811 10:02:40.388318 134875591393280 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0811 10:02:40.389270 134875591393280 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0811 10:02:40.393125 134875591393280 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0811 10:02:40.394177 134875591393280 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0811 10:02:40.395236 134875591393280 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0811 10:02:40.396177 134875591393280 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0811 10:02:40.400640 134875591393280 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0811 10:02:40.401556 134875591393280 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0811 10:02:41.634044 134870346638912 deprecation.py:569] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "I0811 10:02:42.983037 134870346638912 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I0811 10:02:48.028097 134870346638912 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I0811 10:02:52.702104 134870346638912 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I0811 10:02:58.194282 134870346638912 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "INFO:tensorflow:Step 100 per-step time 0.435s\n",
            "I0811 10:03:24.728703 134875591393280 model_lib_v2.py:705] Step 100 per-step time 0.435s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.27954924,\n",
            " 'Loss/localization_loss': 0.3051106,\n",
            " 'Loss/regularization_loss': 0.15230177,\n",
            " 'Loss/total_loss': 0.7369616,\n",
            " 'learning_rate': 0.0319994}\n",
            "I0811 10:03:24.729022 134875591393280 model_lib_v2.py:708] {'Loss/classification_loss': 0.27954924,\n",
            " 'Loss/localization_loss': 0.3051106,\n",
            " 'Loss/regularization_loss': 0.15230177,\n",
            " 'Loss/total_loss': 0.7369616,\n",
            " 'learning_rate': 0.0319994}\n",
            "INFO:tensorflow:Step 200 per-step time 0.108s\n",
            "I0811 10:03:35.552331 134875591393280 model_lib_v2.py:705] Step 200 per-step time 0.108s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20983595,\n",
            " 'Loss/localization_loss': 0.20499761,\n",
            " 'Loss/regularization_loss': 0.15207645,\n",
            " 'Loss/total_loss': 0.56691,\n",
            " 'learning_rate': 0.0373328}\n",
            "I0811 10:03:35.552638 134875591393280 model_lib_v2.py:708] {'Loss/classification_loss': 0.20983595,\n",
            " 'Loss/localization_loss': 0.20499761,\n",
            " 'Loss/regularization_loss': 0.15207645,\n",
            " 'Loss/total_loss': 0.56691,\n",
            " 'learning_rate': 0.0373328}\n",
            "INFO:tensorflow:Step 300 per-step time 0.110s\n",
            "I0811 10:03:46.505504 134875591393280 model_lib_v2.py:705] Step 300 per-step time 0.110s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15977663,\n",
            " 'Loss/localization_loss': 0.14750387,\n",
            " 'Loss/regularization_loss': 0.15183063,\n",
            " 'Loss/total_loss': 0.4591111,\n",
            " 'learning_rate': 0.0426662}\n",
            "I0811 10:03:46.505810 134875591393280 model_lib_v2.py:708] {'Loss/classification_loss': 0.15977663,\n",
            " 'Loss/localization_loss': 0.14750387,\n",
            " 'Loss/regularization_loss': 0.15183063,\n",
            " 'Loss/total_loss': 0.4591111,\n",
            " 'learning_rate': 0.0426662}\n",
            "INFO:tensorflow:Step 400 per-step time 0.109s\n",
            "I0811 10:03:57.360553 134875591393280 model_lib_v2.py:705] Step 400 per-step time 0.109s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12420129,\n",
            " 'Loss/localization_loss': 0.10889331,\n",
            " 'Loss/regularization_loss': 0.15152751,\n",
            " 'Loss/total_loss': 0.3846221,\n",
            " 'learning_rate': 0.047999598}\n",
            "I0811 10:03:57.360859 134875591393280 model_lib_v2.py:708] {'Loss/classification_loss': 0.12420129,\n",
            " 'Loss/localization_loss': 0.10889331,\n",
            " 'Loss/regularization_loss': 0.15152751,\n",
            " 'Loss/total_loss': 0.3846221,\n",
            " 'learning_rate': 0.047999598}\n",
            "INFO:tensorflow:Step 500 per-step time 0.110s\n",
            "I0811 10:04:08.354793 134875591393280 model_lib_v2.py:705] Step 500 per-step time 0.110s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16146521,\n",
            " 'Loss/localization_loss': 0.084030956,\n",
            " 'Loss/regularization_loss': 0.15120395,\n",
            " 'Loss/total_loss': 0.3967001,\n",
            " 'learning_rate': 0.053333}\n",
            "I0811 10:04:08.355100 134875591393280 model_lib_v2.py:708] {'Loss/classification_loss': 0.16146521,\n",
            " 'Loss/localization_loss': 0.084030956,\n",
            " 'Loss/regularization_loss': 0.15120395,\n",
            " 'Loss/total_loss': 0.3967001,\n",
            " 'learning_rate': 0.053333}\n",
            "INFO:tensorflow:Step 600 per-step time 0.108s\n",
            "I0811 10:04:19.146940 134875591393280 model_lib_v2.py:705] Step 600 per-step time 0.108s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07747738,\n",
            " 'Loss/localization_loss': 0.03237449,\n",
            " 'Loss/regularization_loss': 0.15079975,\n",
            " 'Loss/total_loss': 0.26065162,\n",
            " 'learning_rate': 0.0586664}\n",
            "I0811 10:04:19.147232 134875591393280 model_lib_v2.py:708] {'Loss/classification_loss': 0.07747738,\n",
            " 'Loss/localization_loss': 0.03237449,\n",
            " 'Loss/regularization_loss': 0.15079975,\n",
            " 'Loss/total_loss': 0.26065162,\n",
            " 'learning_rate': 0.0586664}\n",
            "INFO:tensorflow:Step 700 per-step time 0.111s\n",
            "I0811 10:04:30.208213 134875591393280 model_lib_v2.py:705] Step 700 per-step time 0.111s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08993551,\n",
            " 'Loss/localization_loss': 0.05616429,\n",
            " 'Loss/regularization_loss': 0.15034139,\n",
            " 'Loss/total_loss': 0.2964412,\n",
            " 'learning_rate': 0.0639998}\n",
            "I0811 10:04:30.208575 134875591393280 model_lib_v2.py:708] {'Loss/classification_loss': 0.08993551,\n",
            " 'Loss/localization_loss': 0.05616429,\n",
            " 'Loss/regularization_loss': 0.15034139,\n",
            " 'Loss/total_loss': 0.2964412,\n",
            " 'learning_rate': 0.0639998}\n",
            "INFO:tensorflow:Step 800 per-step time 0.107s\n",
            "I0811 10:04:40.954165 134875591393280 model_lib_v2.py:705] Step 800 per-step time 0.107s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09107122,\n",
            " 'Loss/localization_loss': 0.08239769,\n",
            " 'Loss/regularization_loss': 0.14983042,\n",
            " 'Loss/total_loss': 0.32329935,\n",
            " 'learning_rate': 0.069333196}\n",
            "I0811 10:04:40.954496 134875591393280 model_lib_v2.py:708] {'Loss/classification_loss': 0.09107122,\n",
            " 'Loss/localization_loss': 0.08239769,\n",
            " 'Loss/regularization_loss': 0.14983042,\n",
            " 'Loss/total_loss': 0.32329935,\n",
            " 'learning_rate': 0.069333196}\n",
            "INFO:tensorflow:Step 900 per-step time 0.109s\n",
            "I0811 10:04:51.840351 134875591393280 model_lib_v2.py:705] Step 900 per-step time 0.109s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06345827,\n",
            " 'Loss/localization_loss': 0.036204837,\n",
            " 'Loss/regularization_loss': 0.1492753,\n",
            " 'Loss/total_loss': 0.24893841,\n",
            " 'learning_rate': 0.074666604}\n",
            "I0811 10:04:51.840714 134875591393280 model_lib_v2.py:708] {'Loss/classification_loss': 0.06345827,\n",
            " 'Loss/localization_loss': 0.036204837,\n",
            " 'Loss/regularization_loss': 0.1492753,\n",
            " 'Loss/total_loss': 0.24893841,\n",
            " 'learning_rate': 0.074666604}\n",
            "INFO:tensorflow:Step 1000 per-step time 0.108s\n",
            "I0811 10:05:02.629642 134875591393280 model_lib_v2.py:705] Step 1000 per-step time 0.108s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07641389,\n",
            " 'Loss/localization_loss': 0.05272653,\n",
            " 'Loss/regularization_loss': 0.1486952,\n",
            " 'Loss/total_loss': 0.2778356,\n",
            " 'learning_rate': 0.08}\n",
            "I0811 10:05:02.629929 134875591393280 model_lib_v2.py:708] {'Loss/classification_loss': 0.07641389,\n",
            " 'Loss/localization_loss': 0.05272653,\n",
            " 'Loss/regularization_loss': 0.1486952,\n",
            " 'Loss/total_loss': 0.2778356,\n",
            " 'learning_rate': 0.08}\n",
            "INFO:tensorflow:Step 1100 per-step time 0.124s\n",
            "I0811 10:05:15.045381 134875591393280 model_lib_v2.py:705] Step 1100 per-step time 0.124s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.082820795,\n",
            " 'Loss/localization_loss': 0.11385797,\n",
            " 'Loss/regularization_loss': 0.14814003,\n",
            " 'Loss/total_loss': 0.34481877,\n",
            " 'learning_rate': 0.07999918}\n",
            "I0811 10:05:15.045723 134875591393280 model_lib_v2.py:708] {'Loss/classification_loss': 0.082820795,\n",
            " 'Loss/localization_loss': 0.11385797,\n",
            " 'Loss/regularization_loss': 0.14814003,\n",
            " 'Loss/total_loss': 0.34481877,\n",
            " 'learning_rate': 0.07999918}\n",
            "INFO:tensorflow:Step 1200 per-step time 0.109s\n",
            "I0811 10:05:25.934161 134875591393280 model_lib_v2.py:705] Step 1200 per-step time 0.109s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06217743,\n",
            " 'Loss/localization_loss': 0.028676549,\n",
            " 'Loss/regularization_loss': 0.14760736,\n",
            " 'Loss/total_loss': 0.23846135,\n",
            " 'learning_rate': 0.079996705}\n",
            "I0811 10:05:25.934469 134875591393280 model_lib_v2.py:708] {'Loss/classification_loss': 0.06217743,\n",
            " 'Loss/localization_loss': 0.028676549,\n",
            " 'Loss/regularization_loss': 0.14760736,\n",
            " 'Loss/total_loss': 0.23846135,\n",
            " 'learning_rate': 0.079996705}\n",
            "INFO:tensorflow:Step 1300 per-step time 0.110s\n",
            "I0811 10:05:36.891266 134875591393280 model_lib_v2.py:705] Step 1300 per-step time 0.110s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06352553,\n",
            " 'Loss/localization_loss': 0.047193706,\n",
            " 'Loss/regularization_loss': 0.14695933,\n",
            " 'Loss/total_loss': 0.25767857,\n",
            " 'learning_rate': 0.0799926}\n",
            "I0811 10:05:36.891613 134875591393280 model_lib_v2.py:708] {'Loss/classification_loss': 0.06352553,\n",
            " 'Loss/localization_loss': 0.047193706,\n",
            " 'Loss/regularization_loss': 0.14695933,\n",
            " 'Loss/total_loss': 0.25767857,\n",
            " 'learning_rate': 0.0799926}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.108s\n",
            "I0811 10:05:47.699955 134875591393280 model_lib_v2.py:705] Step 1400 per-step time 0.108s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05982492,\n",
            " 'Loss/localization_loss': 0.047689933,\n",
            " 'Loss/regularization_loss': 0.14625214,\n",
            " 'Loss/total_loss': 0.253767,\n",
            " 'learning_rate': 0.07998685}\n",
            "I0811 10:05:47.700320 134875591393280 model_lib_v2.py:708] {'Loss/classification_loss': 0.05982492,\n",
            " 'Loss/localization_loss': 0.047689933,\n",
            " 'Loss/regularization_loss': 0.14625214,\n",
            " 'Loss/total_loss': 0.253767,\n",
            " 'learning_rate': 0.07998685}\n",
            "INFO:tensorflow:Step 1500 per-step time 0.109s\n",
            "I0811 10:05:58.602504 134875591393280 model_lib_v2.py:705] Step 1500 per-step time 0.109s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10551514,\n",
            " 'Loss/localization_loss': 0.10238568,\n",
            " 'Loss/regularization_loss': 0.14564623,\n",
            " 'Loss/total_loss': 0.35354704,\n",
            " 'learning_rate': 0.07997945}\n",
            "I0811 10:05:58.602843 134875591393280 model_lib_v2.py:708] {'Loss/classification_loss': 0.10551514,\n",
            " 'Loss/localization_loss': 0.10238568,\n",
            " 'Loss/regularization_loss': 0.14564623,\n",
            " 'Loss/total_loss': 0.35354704,\n",
            " 'learning_rate': 0.07997945}\n",
            "INFO:tensorflow:Step 1600 per-step time 0.109s\n",
            "I0811 10:06:09.467768 134875591393280 model_lib_v2.py:705] Step 1600 per-step time 0.109s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.043826252,\n",
            " 'Loss/localization_loss': 0.03887782,\n",
            " 'Loss/regularization_loss': 0.14499305,\n",
            " 'Loss/total_loss': 0.22769712,\n",
            " 'learning_rate': 0.079970405}\n",
            "I0811 10:06:09.468221 134875591393280 model_lib_v2.py:708] {'Loss/classification_loss': 0.043826252,\n",
            " 'Loss/localization_loss': 0.03887782,\n",
            " 'Loss/regularization_loss': 0.14499305,\n",
            " 'Loss/total_loss': 0.22769712,\n",
            " 'learning_rate': 0.079970405}\n",
            "INFO:tensorflow:Step 1700 per-step time 0.108s\n",
            "I0811 10:06:20.298576 134875591393280 model_lib_v2.py:705] Step 1700 per-step time 0.108s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.068169475,\n",
            " 'Loss/localization_loss': 0.025739994,\n",
            " 'Loss/regularization_loss': 0.14423974,\n",
            " 'Loss/total_loss': 0.23814921,\n",
            " 'learning_rate': 0.07995972}\n",
            "I0811 10:06:20.298928 134875591393280 model_lib_v2.py:708] {'Loss/classification_loss': 0.068169475,\n",
            " 'Loss/localization_loss': 0.025739994,\n",
            " 'Loss/regularization_loss': 0.14423974,\n",
            " 'Loss/total_loss': 0.23814921,\n",
            " 'learning_rate': 0.07995972}\n",
            "INFO:tensorflow:Step 1800 per-step time 0.109s\n",
            "I0811 10:06:31.197105 134875591393280 model_lib_v2.py:705] Step 1800 per-step time 0.109s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07238709,\n",
            " 'Loss/localization_loss': 0.027533343,\n",
            " 'Loss/regularization_loss': 0.1435061,\n",
            " 'Loss/total_loss': 0.24342653,\n",
            " 'learning_rate': 0.0799474}\n",
            "I0811 10:06:31.197433 134875591393280 model_lib_v2.py:708] {'Loss/classification_loss': 0.07238709,\n",
            " 'Loss/localization_loss': 0.027533343,\n",
            " 'Loss/regularization_loss': 0.1435061,\n",
            " 'Loss/total_loss': 0.24342653,\n",
            " 'learning_rate': 0.0799474}\n",
            "INFO:tensorflow:Step 1900 per-step time 0.109s\n",
            "I0811 10:06:42.044075 134875591393280 model_lib_v2.py:705] Step 1900 per-step time 0.109s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08152354,\n",
            " 'Loss/localization_loss': 0.021304209,\n",
            " 'Loss/regularization_loss': 0.14278528,\n",
            " 'Loss/total_loss': 0.24561302,\n",
            " 'learning_rate': 0.07993342}\n",
            "I0811 10:06:42.044408 134875591393280 model_lib_v2.py:708] {'Loss/classification_loss': 0.08152354,\n",
            " 'Loss/localization_loss': 0.021304209,\n",
            " 'Loss/regularization_loss': 0.14278528,\n",
            " 'Loss/total_loss': 0.24561302,\n",
            " 'learning_rate': 0.07993342}\n",
            "INFO:tensorflow:Step 2000 per-step time 0.110s\n",
            "I0811 10:06:53.052702 134875591393280 model_lib_v2.py:705] Step 2000 per-step time 0.110s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.060831036,\n",
            " 'Loss/localization_loss': 0.025400426,\n",
            " 'Loss/regularization_loss': 0.14228714,\n",
            " 'Loss/total_loss': 0.2285186,\n",
            " 'learning_rate': 0.07991781}\n",
            "I0811 10:06:53.053048 134875591393280 model_lib_v2.py:708] {'Loss/classification_loss': 0.060831036,\n",
            " 'Loss/localization_loss': 0.025400426,\n",
            " 'Loss/regularization_loss': 0.14228714,\n",
            " 'Loss/total_loss': 0.2285186,\n",
            " 'learning_rate': 0.07991781}\n"
          ]
        }
      ],
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path=\"ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.config\" \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --num_eval_steps=500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "id": "Is5XPClkl5hl",
        "outputId": "2eec44ec-6d85-4088-b467-e87e37e7ffef"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '/content/training4/train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OayESrYWl_fc",
        "outputId": "0d30ca97-d973-4e73-e3cb-6a5a1224522b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘export’: File exists\n",
            "2023-08-11 10:11:09.388256: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-08-11 10:11:12.819676: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0811 10:11:13.150201 139333871652864 deprecation.py:641] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "I0811 10:11:17.686139 139333871652864 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I0811 10:11:27.578236 139333871652864 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I0811 10:11:30.566758 139333871652864 signature_serialization.py:148] Function `call_func` contains input name(s) resource with unsupported characters which will be renamed to weightsharedconvolutionalboxpredictor_predictiontower_conv2d_3_batchnorm_feature_4_fusedbatchnormv3_readvariableop_1_resource in the SavedModel.\n",
            "I0811 10:11:31.791548 139333871652864 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7eb8adf0e7a0>, because it is not built.\n",
            "W0811 10:11:34.204745 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7eb8adf0e7a0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7eb8adf0efb0>, because it is not built.\n",
            "W0811 10:11:34.491712 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7eb8adf0efb0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb8ac0aa680>, because it is not built.\n",
            "W0811 10:11:34.491913 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb8ac0aa680>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8ac0aad70>, because it is not built.\n",
            "W0811 10:11:34.491994 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8ac0aad70>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7eb8ac0a8310>, because it is not built.\n",
            "W0811 10:11:34.492061 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7eb8ac0a8310>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb8ac0a8760>, because it is not built.\n",
            "W0811 10:11:34.492122 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb8ac0a8760>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8ac0a9360>, because it is not built.\n",
            "W0811 10:11:34.492191 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8ac0a9360>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7eb8ac0a82b0>, because it is not built.\n",
            "W0811 10:11:34.492248 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7eb8ac0a82b0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb8ac0aa560>, because it is not built.\n",
            "W0811 10:11:34.492316 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb8ac0aa560>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8ac0a8910>, because it is not built.\n",
            "W0811 10:11:34.492374 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8ac0a8910>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7eb8ac0abac0>, because it is not built.\n",
            "W0811 10:11:34.492429 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7eb8ac0abac0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb8ac0aa890>, because it is not built.\n",
            "W0811 10:11:34.492486 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb8ac0aa890>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8ac0a9630>, because it is not built.\n",
            "W0811 10:11:34.492542 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8ac0a9630>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb8681baaa0>, because it is not built.\n",
            "W0811 10:11:34.492597 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb8681baaa0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8681bb010>, because it is not built.\n",
            "W0811 10:11:34.492653 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8681bb010>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb8681b8400>, because it is not built.\n",
            "W0811 10:11:34.492713 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb8681b8400>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8681b9900>, because it is not built.\n",
            "W0811 10:11:34.492769 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8681b9900>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb8681ba2f0>, because it is not built.\n",
            "W0811 10:11:34.492824 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb8681ba2f0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8681b80a0>, because it is not built.\n",
            "W0811 10:11:34.492889 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8681b80a0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb8681b98d0>, because it is not built.\n",
            "W0811 10:11:34.492941 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb8681b98d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8681bbb50>, because it is not built.\n",
            "W0811 10:11:34.492994 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8681bbb50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb868199a50>, because it is not built.\n",
            "W0811 10:11:34.493046 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb868199a50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb86819b5e0>, because it is not built.\n",
            "W0811 10:11:34.493101 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb86819b5e0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb86819a290>, because it is not built.\n",
            "W0811 10:11:34.493158 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb86819a290>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb86819a6b0>, because it is not built.\n",
            "W0811 10:11:34.493212 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb86819a6b0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb86819a350>, because it is not built.\n",
            "W0811 10:11:34.493265 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb86819a350>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8681982e0>, because it is not built.\n",
            "W0811 10:11:34.493326 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8681982e0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb86819a980>, because it is not built.\n",
            "W0811 10:11:34.493379 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb86819a980>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb86819b9d0>, because it is not built.\n",
            "W0811 10:11:34.493434 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb86819b9d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb868199f60>, because it is not built.\n",
            "W0811 10:11:34.493487 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb868199f60>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8a0088910>, because it is not built.\n",
            "W0811 10:11:34.493541 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8a0088910>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb8a008a4a0>, because it is not built.\n",
            "W0811 10:11:34.493595 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb8a008a4a0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8a008bfa0>, because it is not built.\n",
            "W0811 10:11:34.493648 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8a008bfa0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb8a0089cc0>, because it is not built.\n",
            "W0811 10:11:34.493701 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb8a0089cc0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8a008a890>, because it is not built.\n",
            "W0811 10:11:34.493754 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8a008a890>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb8a008b760>, because it is not built.\n",
            "W0811 10:11:34.493806 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb8a008b760>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8a0088280>, because it is not built.\n",
            "W0811 10:11:34.493869 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb8a0088280>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb86815e290>, because it is not built.\n",
            "W0811 10:11:34.493925 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb86815e290>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb86815e200>, because it is not built.\n",
            "W0811 10:11:34.493979 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb86815e200>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb86815eb00>, because it is not built.\n",
            "W0811 10:11:34.494032 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb86815eb00>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb86815c310>, because it is not built.\n",
            "W0811 10:11:34.494086 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb86815c310>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb86815f190>, because it is not built.\n",
            "W0811 10:11:34.494149 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb86815f190>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb86815d5a0>, because it is not built.\n",
            "W0811 10:11:34.494205 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb86815d5a0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb86815ef80>, because it is not built.\n",
            "W0811 10:11:34.494259 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7eb86815ef80>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb86815c940>, because it is not built.\n",
            "W0811 10:11:34.564635 139333871652864 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7eb86815c940>, because it is not built.\n",
            "I0811 10:11:47.348270 139333871652864 save.py:274] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 173). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: export2/saved_model/assets\n",
            "I0811 10:11:52.893704 139333871652864 builder_impl.py:804] Assets written to: export2/saved_model/assets\n",
            "I0811 10:11:53.206316 139333871652864 fingerprinting_utils.py:48] Writing fingerprint to export2/saved_model/fingerprint.pb\n",
            "INFO:tensorflow:Writing pipeline config file to export2/pipeline.config\n",
            "I0811 10:11:53.726474 139333871652864 config_util.py:253] Writing pipeline config file to export2/pipeline.config\n"
          ]
        }
      ],
      "source": [
        "!mkdir \"export\"\n",
        "\n",
        "!python \"/content/models/research/object_detection/exporter_main_v2.py\" --input_type='image_tensor' --pipeline_config_path=\"ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.config\" --trained_checkpoint_dir=\"/content/training4\" --output_directory=\"export2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OupckURnTT-"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = tf.saved_model.load(f'/content/export2/saved_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVzGdRkuoFTu"
      },
      "outputs": [],
      "source": [
        "from six import BytesIO\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: a file path (this can be local or on colossus)\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LWZlNfYFeTw"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xvinj9zloKv7"
      },
      "outputs": [],
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap('labelmap.pbtxt', use_display_name=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rstMnRynkSL"
      },
      "outputs": [],
      "source": [
        "def run_inference_for_single_image(model, image):\n",
        "  image = np.asarray(image)\n",
        "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "  input_tensor = input_tensor[tf.newaxis,...]\n",
        "\n",
        "  # Run inference\n",
        "  model_fn = model.signatures['serving_default']\n",
        "  output_dict = model_fn(input_tensor)\n",
        "\n",
        "  # All outputs are batches tensors.\n",
        "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "  # We're only interested in the first num_detections.\n",
        "  num_detections = int(output_dict.pop('num_detections'))\n",
        "  output_dict = {key:value[0, :num_detections].numpy()\n",
        "                 for key,value in output_dict.items()}\n",
        "  output_dict['num_detections'] = num_detections\n",
        "\n",
        "  # detection_classes should be ints.\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
        "\n",
        "  # Handle models with masks:\n",
        "  if 'detection_masks' in output_dict:\n",
        "    # Reframe the the bbox mask to the image size.\n",
        "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
        "               image.shape[0], image.shape[1])\n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
        "                                       tf.uint8)\n",
        "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "\n",
        "  return output_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M83OAyFVnmTq",
        "outputId": "fee1dbdb-b659-4c2c-a246-6dddb514658f"
      },
      "outputs": [],
      "source": [
        "for image_path in glob.glob('/content/data/images/source/*.png'):\n",
        "  image_np = load_image_into_numpy_array(image_path)\n",
        "  output_dict = run_inference_for_single_image(model, image_np)\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=8)\n",
        "  display(Image.fromarray(image_np))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNPWrSCjYteTRjcZWamXT0S",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}